Procedura:
	- Download sorgente Spark
	- Modificare il Dockerfile di Spark per sostituire kubernetes-client-4.1.2.jar con kubernetes-client-4.4.2.jar
	- Buildare Spark su Docker utilizzando la SPARK_HOME come directory base
	- Scrivere un applicazione Java che sfrutti Spark ed utilizzare la precedente immagine Docker come immagine base
	- Installare helm sulla macchina cos√¨ da installare l'estensione SparkOperator di Kubernetes
	- Installare un MongoDB e far si che alla creazione sia inizializzato in replica e con le collection necessarie
	- Installare Kafka e Zookeeper
	- Installare Kafka Connect, predisponendo n file nelle secret (anche nella solita). I file conterranno i json da inviare al connect per abilitare l'ascolto su MongoDB
	- Lanciare l'applicativo Java con Kind SparkApplication
	- Download sorgente Zeppelin
	- Modificare il file 100-interpreter-spec.yaml per configurare eventuali interpreti aggiuntivi, prevedere pvc e configurazioni, in particolare env SPARK_SUBMIT_OPTIONS=--conf spark.kubernetes.executor.volumes.persistentVolumeClaim.parquet-pvc.mount.path=/zeppelin/k8s-custom
	- Build package delle sorgenti Zeppelin
	- Modificare il Dockerfile commentando la parte dove si scarica le sorgenti da git e sostituendo il jar necessario con quello appena buildato e presente sotto la folder target
	- Lanciare tutti i componenti su K8s